# Lab1: Back Propagation

1. Change hyperparameters in `config.json` 
    - **data_type**: data type, `linear` or `xor`
    - **epoch**: training epoch, default is `1000000`
    - **learning_rate**: learning rate, default is `0.1`
    - **activation**: activation function, `no` or `sigmoid` or `tanh` or `relu` or `leaky_relu`
    - **optimizer**: learning rate optimizer, `no` or `momentum` or `adagrad` or `adam`
2. Train and test the model
    
    ```
    python Lab/Lab1_Back_Propagation/code/main.py
    ```
    
3. Show the result
